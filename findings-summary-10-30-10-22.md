- Baseline findings: Load tests pinned commit latency on `WALSync/WALWrite`; nearly every single-statement transaction forced its own fsync, Debezium `REPLICA IDENTITY FULL` inflated row images, and dead tuples piled up on document/alias partitions despite autovacuum keeping pace.
- 2025-10-26 remediation: Removing logical replication artifacts and dropping the authorization JSONB column cleared sustained WAL waits (nvme flush ≈0.13 ms) and shrank dead tuples from ~50 k to ~5 k per partition, shifting the bottleneck from storage to commit rate management.
- 2025-10-26 16:41 gains: Adding the alias FK index plus config tuning cut cascade deletes from 215 ms full scans to 0.38 ms indexed probes, while 2.8 k commits/s at ~0.33 ms per flush confirmed the WAL path had headroom and that application CPU now dominated host load.
- 2025-10-26 17:28 posture: Re-enabling `wal_level=logical` added 10–12 % WAL overhead yet kept flush latency ~0.19 ms and autovacuum healthy, proving the platform can sustain logical decoding once archives are sized for the higher byte rate.
- 2025-10-27 18:46 momentum: Sequential DocumentUuid generation and new WAL timers showed group commit efficiency (~0.55 flushes per commit, 55 MB/30 s) with dead tuples capped at 1–7 k, leaving DMS-side CPU and temp-file workloads as the emerging ceiling.
- 2025-10-27 22:15 refinement: The PG 18 upgrade maintained sub-ms query and WAL performance (473 MB/30 s at 0.33 ms/flush) but exposed operational asks—tame 2 GB autovacuum workers, clean up DISCARD ALL storms, and enforce prompt closeout of `SELECT FOR UPDATE` sessions.
- 2025-10-29 15:57 inflection: Loading the reference dataset drove sustained 17 MB/s WAL and surfaced 101 ms joins from partition-mismatch scans, while aggressive `work_mem`/`maintenance_work_mem` pushed swap to 7 GB/8 GB and let autovacuum lag on the new partitions.
- Current focus: Batch or relax synchronous commits, re-partition or globally index the reference workload, right-size memory knobs, profile DMS CPU hot spots, and keep per-run pg_stat_wal/io/statements snapshots plus idle-in-transaction hygiene to hold the WAL path steady as load grows.
